"""add hierarchical indices columns

Revision ID: 001_hierarchical_indices
Revises:
Create Date: 2025-11-16 14:30:00.000000

"""
from alembic import op
import sqlalchemy as sa
from pgvector.sqlalchemy import Vector


# revision identifiers, used by Alembic.
revision = '001_hierarchical_indices'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    """
    Add document_embedding and summary columns to documents table for hierarchical search.

    These columns enable two-tier retrieval:
    - document_embedding: Vector(1536) for document-level semantic search
    - summary: Text summary used to generate document_embedding

    This allows hierarchical search: document â†’ chunk, reducing search space
    and improving accuracy by 20-30%.
    """
    # Add document_embedding column (nullable for existing documents)
    op.add_column('documents', sa.Column('document_embedding', Vector(1536), nullable=True))

    # Add summary column (nullable for existing documents)
    op.add_column('documents', sa.Column('summary', sa.Text(), nullable=True))

    # Create index on document_embedding for fast document-level similarity search
    # Using ivfflat index for approximate nearest neighbor search
    # lists=100 is a good default for collections up to 1M documents
    op.execute("""
        CREATE INDEX IF NOT EXISTS idx_documents_embedding
        ON documents
        USING ivfflat (document_embedding vector_cosine_ops)
        WITH (lists = 100)
    """)


def downgrade() -> None:
    """
    Remove hierarchical indices columns and index.

    Warning: This will delete all document embeddings and summaries.
    """
    # Drop index first
    op.execute("DROP INDEX IF EXISTS idx_documents_embedding")

    # Drop columns
    op.drop_column('documents', 'summary')
    op.drop_column('documents', 'document_embedding')
